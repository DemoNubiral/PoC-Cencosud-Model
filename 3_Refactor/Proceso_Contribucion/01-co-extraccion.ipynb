{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c6919a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "It looks like there is a newer version of the kernel available. The latest version is 1.0.9 and you have 1.0.8 installed.\n",
      "Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n",
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::116948010203:role/Poc-alertas-glue.\n",
      "Previous region: us-east-1\n",
      "Setting new region to: us-east-1\n",
      "Region is set to: us-east-1\n",
      "Tag {'creado-por': 'santiago.castro@externos-cl.cencosud.com', 'apl': 'apl1214', 'unidad-negocio': 'ccom', 'bandera': 'cencommerce', 'plataforma': 'eks', 'version-so': '1.25', 'Name': 'CO-ALERT-POC', 'ambiente': 'staging', 'cuenta': '116948010203', 'pais': 'co', 'ceco': 'CVO1007301', 'Terraform': 'no', 'environment': 'staging', 'aplicacion': 'co alert poc', 'ApplicationName': 'CO-ALERT-POC', 'propietario': 'humbertolares@cencosud.cl', 'proyecto': 'CENCO-PIM', 'epm': 'opex', 'Owner': 'Humberto Lares', 'tribe': 'Digital Retail Backbone'} added\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::116948010203:role/Poc-alertas-glue\n",
    "\n",
    "%region us-east-1\n",
    "\n",
    "%%tags\n",
    "{\n",
    "    \"creado-por\": \"santiago.castro@externos-cl.cencosud.com\",\n",
    "    \"apl\": \"apl1214\",\n",
    "    \"unidad-negocio\": \"ccom\",\n",
    "    \"bandera\": \"cencommerce\",\n",
    "    \"plataforma\": \"eks\",\n",
    "    \"version-so\": \"1.25\",\n",
    "    \"Name\": \"CO-ALERT-POC\",\n",
    "    \"ambiente\": \"staging\",\n",
    "    \"cuenta\": \"116948010203\",\n",
    "    \"pais\": \"co\",\n",
    "    \"ceco\": \"CVO1007301\",\n",
    "    \"Terraform\": \"no\",\n",
    "    \"environment\": \"staging\",\n",
    "    \"aplicacion\": \"co alert poc\",\n",
    "    \"ApplicationName\": \"CO-ALERT-POC\",\n",
    "    \"propietario\": \"humbertolares@cencosud.cl\",\n",
    "    \"proyecto\": \"CENCO-PIM\",\n",
    "    \"epm\": \"opex\",\n",
    "    \"Owner\": \"Humberto Lares\",\n",
    "    \"tribe\": \"Digital Retail Backbone\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2d780",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current idle_timeout is None minutes.\n",
      "idle_timeout has been set to 10 minutes.\n",
      "Setting Glue version to: 5.0\n",
      "Previous worker type: None\n",
      "Setting new worker type to: G.1X\n",
      "Previous number of workers: None\n",
      "Setting new number of workers to: 4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%idle_timeout 10\n",
    "%glue_version 5.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7ef9d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e98a9d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd71f35",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from gcpspark import create_pyspark\n",
    "from pyspark.sql.functions import col, current_date, date_sub\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Configuración de entorno\n",
    "ENV = os.environ[\"ENVIRONMENT\"]\n",
    "\n",
    "properties = {\n",
    "    \"accesskey\": os.getenv(\"colombia_sm_aws_access_key_id\"),\n",
    "    \"secretkey\": os.getenv(\"colombia_sm_aws_secret_access_key\"),\n",
    "    \"sas_url\": \"\",\n",
    "    \"sas\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b953ea7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializar SparkSession con conexión a S3\n",
    "spark_name = \"data-extraction-br\"\n",
    "spark = create_pyspark(name=spark_name, connection=\"s3\", properties=properties, verbose=True)\n",
    "\n",
    "# --- Funciones de transformación ---\n",
    "\n",
    "def transformation_stock(df):\n",
    "    \"\"\"Filtra stock del día anterior y unidades mayores a cero.\"\"\"\n",
    "    return (\n",
    "        df.select(\"tienda_stock\", \"sku_stock\", \"ean_stock\", \"fecha_stock\", \"unidades_stock\")\n",
    "          .filter(col(\"fecha_stock\") == date_sub(current_date(), 1))\n",
    "          .filter(col(\"unidades_stock\") > 0)\n",
    "    )\n",
    "\n",
    "def transformation_active(df):\n",
    "    \"\"\"Filtra productos activos ('estado_producto' == 'S').\"\"\"\n",
    "    return df.filter(col(\"estado_producto\") == \"S\").drop(\"estado_producto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec23dc",
   "metadata": {},
   "source": [
    "Maestra_Activa_Colombia* → BQ_CO_SM_ACTIVE_01\n",
    "\n",
    "Maestra_Canal_Ventas_Colombia* → BQ_CO_SM_CHANNELS_01\n",
    "\n",
    "Maestra_Promocion_Colombia* → BQ_CO_SM_PROMOTIONS_01\n",
    "\n",
    "Maestra_Tienda_Colombia* → BQ_CO_SM_STORES_01\n",
    "\n",
    "Productos_Arcus_Colombia* → BQ_CO_SM_PRODUCTS_01\n",
    "\n",
    "Ventas_Arcus_Colombia* → BQ_CO_SM_SALES_01\n",
    "\n",
    "Stock_Arcus_Colombia* → BQ_CO_SM_STOCK_01\n",
    "\n",
    "Stock_Arcus_Colombia* → también se ejecuta semanalmente, además de diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac83b0b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# --- Configuración de fuentes ---\n",
    "\n",
    "bucket_name = \"cencosud.prod.sandbox.sm.col\"\n",
    "\n",
    "sources = [\n",
    "    \n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Maestra_Activa_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_ACTIVE_01\",\n",
    "        \"mode\": \"overwrite\",\n",
    "        \"transformation\": transformation_active\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Maestra_Canal_Ventas_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_CHANNELS_01\",\n",
    "        \"mode\": \"overwrite\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Maestra_Promocion_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_PROMOTIONS_01\",\n",
    "        \"mode\": \"overwrite\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Maestra_Tienda_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_STORES_01\",\n",
    "        \"mode\": \"overwrite\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Productos_Arcus_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_PRODUCTS_01\",\n",
    "        \"mode\": \"append\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Ventas_Arcus_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_SALES_01\",\n",
    "        \"mode\": \"append\"\n",
    "    },\n",
    "    {\n",
    "        \"prefix\": \"ANALYTICS/ARCUS/Stock_Arcus_Colombia*\",\n",
    "        \"bucket\": f\"{ENV}-bucket-dataproc-bigquery/dataproc/co_extraction\",\n",
    "        \"table\": \"data_analytics_default.BQ_CO_SM_STOCK_01\",\n",
    "        \"mode\": \"overwrite\",\n",
    "        \"transformation\": transformation_stock\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf96d4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today().weekday()  # 0 = lunes\n",
    "\n",
    "# Tablas que solo se ejecutan los lunes\n",
    "weekly_tables = {\n",
    "    \"data_analytics_default.BQ_CO_SM_ACTIVE_01\",\n",
    "    \"data_analytics_default.BQ_CO_SM_CHANNELS_01\",\n",
    "    \"data_analytics_default.BQ_CO_SM_PROMOTIONS_01\",\n",
    "    \"data_analytics_default.BQ_CO_SM_STORES_01\",\n",
    "    \"data_analytics_default.BQ_CO_SM_PRODUCTS_01\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22600eaa",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# --- Proceso por cada fuente ---\n",
    "\n",
    "for source in sources:\n",
    "    table_name = source[\"table\"]\n",
    "    \n",
    "    if table_name in weekly_tables and today != 0:\n",
    "        logging.info(f\"Saltando tabla {table_name} (frecuencia semanal, hoy no es lunes).\")\n",
    "        continue\n",
    "\n",
    "    prefix = source[\"prefix\"]\n",
    "    gcs_temp_bucket = source[\"bucket\"]\n",
    "    \n",
    "    logging.info(f\"Iniciando procesamiento para tabla: {table_name}\")\n",
    "    data_loaded = False\n",
    "    retries = 17\n",
    "    start_time = time.time()\n",
    "\n",
    "    while not data_loaded and retries > 0:\n",
    "        df = spark.read.parquet(f\"s3a://{bucket_name}/{prefix}\")\n",
    "\n",
    "        # Aplicar transformación si existe\n",
    "        if \"transformation\" in source:\n",
    "            df = source[\"transformation\"](df)\n",
    "\n",
    "        # Validar si hay datos\n",
    "        has_data = df.limit(1).count() > 0\n",
    "\n",
    "        if has_data:\n",
    "            data_loaded = True\n",
    "            df = df.cache()  # cache si se va a usar varias veces\n",
    "        else:\n",
    "            logging.warning(\"No hay datos nuevos. Reintentando en 10 minutos...\")\n",
    "            retries -= 1\n",
    "            time.sleep(600)\n",
    "\n",
    "    if not data_loaded:\n",
    "        logging.warning(f\"No se encontró información para la tabla {table_name} tras múltiples intentos.\")\n",
    "        continue\n",
    "\n",
    "    if source[\"mode\"] == \"overwrite\":\n",
    "        df.write.format(\"bigquery\") \\\n",
    "            .option(\"temporaryGcsBucket\", gcs_temp_bucket) \\\n",
    "            .option(\"table\", table_name) \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save()\n",
    "        logging.info(f\"Datos sobreescritos en {table_name}\")\n",
    "    else:\n",
    "        # Append condicional solo si hay datos nuevos únicos\n",
    "        historical_df = spark.read.format(\"bigquery\") \\\n",
    "            .option(\"table\", table_name) \\\n",
    "            .load() \\\n",
    "            .drop(\"_PARTITIONTIME\", \"_PARTITIONDATE\")\n",
    "\n",
    "        new_unique_df = df.exceptAll(historical_df)\n",
    "        new_count = new_unique_df.limit(1).count()\n",
    "\n",
    "        if new_count == 0:\n",
    "            logging.info(f\"No se encontraron registros únicos nuevos para {table_name}.\")\n",
    "            continue\n",
    "\n",
    "        new_unique_df.write.format(\"bigquery\") \\\n",
    "            .option(\"temporaryGcsBucket\", gcs_temp_bucket) \\\n",
    "            .option(\"table\", table_name) \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "        logging.info(f\"{new_count} registros únicos agregados a {table_name}.\")\n",
    "\n",
    "    duration = round((time.time() - start_time)/60, 2)\n",
    "    logging.info(f\"Proceso completado para {table_name} en {duration} minutos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb8d03",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Cerrar sesión Spark\n",
    "spark.stop()\n",
    "logging.info(\"Proceso finalizado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
