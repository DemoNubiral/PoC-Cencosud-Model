{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4346318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "It looks like there is a newer version of the kernel available. The latest version is 1.0.9 and you have 1.0.8 installed.\n",
      "Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n",
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::116948010203:role/Poc-alertas-glue.\n",
      "Previous region: us-east-1\n",
      "Setting new region to: us-east-1\n",
      "Region is set to: us-east-1\n",
      "Tag {'creado-por': 'santiago.castro@externos-cl.cencosud.com', 'apl': 'apl1214', 'unidad-negocio': 'ccom', 'bandera': 'cencommerce', 'plataforma': 'eks', 'version-so': '1.25', 'Name': 'CO-ALERT-POC', 'ambiente': 'staging', 'cuenta': '116948010203', 'pais': 'co', 'ceco': 'CVO1007301', 'Terraform': 'no', 'environment': 'staging', 'aplicacion': 'co alert poc', 'ApplicationName': 'CO-ALERT-POC', 'propietario': 'humbertolares@cencosud.cl', 'proyecto': 'CENCO-PIM', 'epm': 'opex', 'Owner': 'Humberto Lares', 'tribe': 'Digital Retail Backbone'} added\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::116948010203:role/Poc-alertas-glue\n",
    "\n",
    "%region us-east-1\n",
    "\n",
    "%%tags\n",
    "{\n",
    "    \"creado-por\": \"santiago.castro@externos-cl.cencosud.com\",\n",
    "    \"apl\": \"apl1214\",\n",
    "    \"unidad-negocio\": \"ccom\",\n",
    "    \"bandera\": \"cencommerce\",\n",
    "    \"plataforma\": \"eks\",\n",
    "    \"version-so\": \"1.25\",\n",
    "    \"Name\": \"CO-ALERT-POC\",\n",
    "    \"ambiente\": \"staging\",\n",
    "    \"cuenta\": \"116948010203\",\n",
    "    \"pais\": \"co\",\n",
    "    \"ceco\": \"CVO1007301\",\n",
    "    \"Terraform\": \"no\",\n",
    "    \"environment\": \"staging\",\n",
    "    \"aplicacion\": \"co alert poc\",\n",
    "    \"ApplicationName\": \"CO-ALERT-POC\",\n",
    "    \"propietario\": \"humbertolares@cencosud.cl\",\n",
    "    \"proyecto\": \"CENCO-PIM\",\n",
    "    \"epm\": \"opex\",\n",
    "    \"Owner\": \"Humberto Lares\",\n",
    "    \"tribe\": \"Digital Retail Backbone\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6c8a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current idle_timeout is None minutes.\n",
      "idle_timeout has been set to 15 minutes.\n",
      "Setting Glue version to: 5.0\n",
      "Previous worker type: None\n",
      "Setting new worker type to: G.1X\n",
      "Previous number of workers: None\n",
      "Setting new number of workers to: 4\n"
     ]
    }
   ],
   "source": [
    "%idle_timeout 15\n",
    "%glue_version 5.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cdf846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# --- Configurar logging para Glue Job (CloudWatch compatible) ---\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --- Función de log personalizada para mantener formato uniforme ---\n",
    "def log(msg, level=\"INFO\"):\n",
    "    if level == \"INFO\":\n",
    "        logger.info(msg)\n",
    "    elif level == \"WARNING\":\n",
    "        logger.warning(msg)\n",
    "    elif level == \"ERROR\":\n",
    "        logger.error(msg)\n",
    "    else:\n",
    "        logger.debug(msg)\n",
    "\n",
    "# --- Inicializar GlueContext ---\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# --- Rutas de origen y destino en S3 ---\n",
    "BUCKET_LANDING = \"s3://landing-data-poc-cl2025/\"\n",
    "BUCKET_STAGE = \"s3://stage-data-poc-cl2025/\"\n",
    "\n",
    "table_id = 'BQ_CO_SM_SALES_01/'\n",
    "table_id2 = 'BQ_CO_SM_SALES_02/'\n",
    "\n",
    "TABLE = f\"{BUCKET_LANDING}{table_id}\"\n",
    "TABLE2 = f\"{BUCKET_STAGE}{table_id2}\"\n",
    "\n",
    "# --- Lectura desde S3 (Parquet) ---\n",
    "log(f\"Leyendo datos desde: {TABLE}\")\n",
    "df = spark.read.parquet(TABLE)\n",
    "log(f\"Filas leídas: {df.count()}\")\n",
    "\n",
    "# --- Transformación ---\n",
    "log(\"Transformando columnas y filtrando UNITS > 0...\")\n",
    "df_transformed = (\n",
    "    df.select(\"ean_venta\", \"sku_venta\", \"tienda_venta\", \"fecha_venta\", \"unidades_venta\")\n",
    "      .withColumnRenamed(\"tienda_venta\", \"LOCAL_ID\")\n",
    "      .withColumnRenamed(\"sku_venta\", \"ITEM_ID\")\n",
    "      .withColumnRenamed(\"ean_venta\", \"EAN\")\n",
    "      .withColumnRenamed(\"fecha_venta\", \"DATE\")\n",
    "      .withColumnRenamed(\"unidades_venta\", \"UNITS\")\n",
    "      .filter(F.col(\"UNITS\") > 0)\n",
    ")\n",
    "\n",
    "log(f\"Filas luego de la transformación: {df_transformed.count()}\")\n",
    "\n",
    "# --- Escritura a S3 destino ---\n",
    "log(f\"Escribiendo datos transformados en: {TABLE2}\")\n",
    "df_transformed.write.mode(\"overwrite\").parquet(TABLE2)\n",
    "\n",
    "log(\"Proceso completado correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
