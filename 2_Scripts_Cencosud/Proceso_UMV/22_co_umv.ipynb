{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bd87f1-af62-4a06-b850-e429f6b4d3a5",
   "metadata": {},
   "source": [
    "# **<font color='black'>COLOMBIA</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99c5ab0b-3cae-424e-8649-e7716151d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pyspark\").setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Paquetes (checar o que preciso e o que não preciso)\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "#logging.getLogger(\"py4j.java_gateway\").setLevel(logging.ERROR)\n",
    "import shutil\n",
    "\n",
    "from datetime import date, datetime, timedelta, date\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import scipy.stats as sps\n",
    "import seaborn as sns\n",
    "import matplotlib as m\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.pylab import rcParams\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import requests\n",
    "from statsforecast.arima import AutoARIMA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from prophet import Prophet\n",
    "\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import dotenv\n",
    "from gcpspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_date, date_sub, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5d28898-33f8-4e25-9aa5-a5187b84001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'data_analytics_default'\n",
    "table_id = 'BQ_CO_SM_SALES_02'\n",
    "ENV = os.environ[\"ENVIRONMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c22fdb1-ffad-4cae-bcc0-a46785b39a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cota_recencia = 3\n",
    "cota_frecuencia = 180\n",
    "cota_latencia = 2\n",
    "cota_mediana = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb413bfb-178a-4343-8842-60ce8a692cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE = 2\n",
    "COTA_MAPE_MODELS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd14f18-9203-4b1f-8f0c-ce59679ad730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "# Get the day of the week (0 = Monday, 1 = Tuesday, ..., 6 = Sunday)\n",
    "day_of_week = current_date.weekday()\n",
    "# Set MONDAY variable\n",
    "MONDAY = day_of_week == 0 or True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34173517-c9f2-421a-a242-3a3bdb74a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha Inicio 2023-05-19\n",
      "Fecha Entranmiento 2024-05-12\n",
      "Fecha Ejecucion 2024-05-20\n",
      "Fecha Prediccion 2024-05-27\n"
     ]
    }
   ],
   "source": [
    "# Fechas de ejecución, entreinamiento y inicio y historial de 13 meses\n",
    "fecha_ejecucion = date.today() - timedelta(days = datetime.weekday(date.today())) - timedelta(days = 0)\n",
    "fecha_train = fecha_ejecucion - timedelta(days = 8)\n",
    "\n",
    "mes = 12\n",
    "\n",
    "fecha_inicio = fecha_train -  timedelta(days = 30 * mes - 1)\n",
    "\n",
    "print(\"Fecha Inicio\",fecha_inicio)\n",
    "print(\"Fecha Entranmiento\",fecha_train)\n",
    "print(\"Fecha Ejecucion\",fecha_ejecucion)\n",
    "print(\"Fecha Prediccion\",fecha_ejecucion + timedelta(days = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3594f9a9-dbe0-4c06-865a-e0002ba88409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at: /jars/spark-bigquery-with-dependencies_2.12-0.26.0.jar\n",
      "File already exists at: /jars/gcs-connector-hadoop3-2.2.19.jar\n",
      "Process: co_umv_umv_1716490589718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: viewsEnabled\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Spark Session\n",
    "spark = create_pyspark(name=\"co_umv_umv\", connection=\"GCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ed941ad-48c2-4dd1-a291-7187a4b24bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EAN: string (nullable = true)\n",
      " |-- ITEM_ID: string (nullable = true)\n",
      " |-- LOCAL_ID: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- UNITS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data collection\n",
    "df = (\n",
    "    spark.read.format(\"bigquery\")\n",
    "    .option(\"table\", f\"{dataset_id}.{table_id}\")\n",
    "    .load()\n",
    ")\n",
    "# print(df.count())\n",
    "df = df.drop(\"_PARTITIONTIME\", \"_PARTITIONDATE\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b2753c7-2bc9-420a-905f-90ebe0e31feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transaccional = df.groupBy(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\", \"DATE\")\\\n",
    "                        .agg(F.sum(\"UNITS\").alias(\"y\"))\\\n",
    "                        .withColumnRenamed(\"DATE\", \"ds\").na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7704616d-56c2-4058-a9ec-0123a8a7bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outliers = spark.read.format(\"bigquery\").option(\"table\",\"data_analytics_default.BQ_CO_SM_SALES_03\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "487f3f73-2aa3-49fb-a548-caeb40fd10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(DISTINCT LOCAL_ID)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(DISTINCT LOCAL_ID)\n",
       "0                       114"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.select(F.countDistinct(\"LOCAL_ID\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06f469e3-e761-44ac-8285-4a2784b4dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPO</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>671160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>34516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>671160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIPO     count\n",
       "0  VALIDATE    671160\n",
       "1     TRAIN  34516800\n",
       "2      TEST    671160"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.groupBy(F.col(\"TIPO\")).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "154b7bc7-4ea4-4ffd-b890-ec2030a24a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DIA</th>\n",
       "      <th>ds</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>y</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-05-25</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0002830</td>\n",
       "      <td>7702024004677</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-05-25</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002830-0002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0002830</td>\n",
       "      <td>7702024004677</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002830-0002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0002830</td>\n",
       "      <td>7702024004677</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002830-0002830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCAL_ID  ITEM_ID            EAN  DIA          ds      TIPO    y  \\\n",
       "0       10  0002592  7702032253135    5  2024-05-23  VALIDATE  1.0   \n",
       "1       10  0002592  7702032253135    2  2024-05-20  VALIDATE  2.0   \n",
       "2       10  0002592  7702032253135    6  2024-05-24  VALIDATE  2.0   \n",
       "3       10  0002592  7702032253135    7  2024-05-25  VALIDATE  3.0   \n",
       "4       10  0002592  7702032253135    4  2024-05-22  VALIDATE  1.0   \n",
       "5       10  0002592  7702032253135    3  2024-05-21  VALIDATE  2.0   \n",
       "6       10  0002592  7702032253135    1  2024-05-26  VALIDATE  3.0   \n",
       "7       10  0002830  7702024004677    7  2024-05-25  VALIDATE  2.0   \n",
       "8       10  0002830  7702024004677    3  2024-05-21  VALIDATE  2.0   \n",
       "9       10  0002830  7702024004677    1  2024-05-26  VALIDATE  2.0   \n",
       "\n",
       "                   ID  \n",
       "0  10-0002592-0002592  \n",
       "1  10-0002592-0002592  \n",
       "2  10-0002592-0002592  \n",
       "3  10-0002592-0002592  \n",
       "4  10-0002592-0002592  \n",
       "5  10-0002592-0002592  \n",
       "6  10-0002592-0002592  \n",
       "7  10-0002830-0002830  \n",
       "8  10-0002830-0002830  \n",
       "9  10-0002830-0002830  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.filter(F.col(\"TIPO\")==\"VALIDATE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b8bc75-234e-4403-8328-38b6790f39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>count(ITEM_ID)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>27</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>83</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>108</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>148</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>16</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOCAL_ID  count(ITEM_ID)\n",
       "0       203               1\n",
       "1       123               2\n",
       "2       204               3\n",
       "3       159               3\n",
       "4        11               4\n",
       "..      ...             ...\n",
       "95       27            1587\n",
       "96       83            1593\n",
       "97      108            1687\n",
       "98      148            1706\n",
       "99       16            1765\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.groupBy(F.col(\"LOCAL_ID\")).agg(F.countDistinct(\"ITEM_ID\")).orderBy(\"count(ITEM_ID)\"),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f577062-20f8-4890-a798-d81d7dc01fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>count(ITEM_ID)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>806</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>103</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>13</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>15</td>\n",
       "      <td>3912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>14</td>\n",
       "      <td>4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>19</td>\n",
       "      <td>5390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOCAL_ID  count(ITEM_ID)\n",
       "0       301             111\n",
       "1       333             119\n",
       "2       806             130\n",
       "3       105             147\n",
       "4       304             150\n",
       "..      ...             ...\n",
       "76      103            2699\n",
       "77       13            2930\n",
       "78       15            3912\n",
       "79       14            4073\n",
       "80       19            5390\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.groupBy(F.col(\"LOCAL_ID\")).agg(F.countDistinct(\"ITEM_ID\")).filter(F.col(\"count(ITEM_ID)\")>100).orderBy(\"count(ITEM_ID)\"),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b00e75bb-adcc-42bf-9404-8cd53d05089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(count(ITEM_ID))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841.052632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(count(ITEM_ID))\n",
       "0           841.052632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers.groupBy(F.col(\"LOCAL_ID\")).agg(F.countDistinct(\"ITEM_ID\")).select(F.avg(\"count(ITEM_ID)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41978bd5-8f83-4fd2-af9d-ae5f2e52af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outliers = data_outliers.repartition(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af176b0f-c145-443f-beec-2fb68a42f88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DIA</th>\n",
       "      <th>ds</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>y</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0002592</td>\n",
       "      <td>7702032253135</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10-0002592-0002592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCAL_ID  ITEM_ID            EAN  DIA          ds   TIPO    y  \\\n",
       "0       10  0002592  7702032253135    5  2023-10-12  TRAIN  1.0   \n",
       "1       10  0002592  7702032253135    5  2024-01-11  TRAIN  1.0   \n",
       "2       10  0002592  7702032253135    5  2024-02-22  TRAIN  2.0   \n",
       "3       10  0002592  7702032253135    5  2023-06-29  TRAIN  1.0   \n",
       "4       10  0002592  7702032253135    5  2023-11-30  TRAIN  1.0   \n",
       "5       10  0002592  7702032253135    5  2024-02-01  TRAIN  1.0   \n",
       "6       10  0002592  7702032253135    5  2023-06-08  TRAIN  1.0   \n",
       "7       10  0002592  7702032253135    5  2023-11-02  TRAIN  2.0   \n",
       "8       10  0002592  7702032253135    5  2023-09-21  TRAIN  1.0   \n",
       "9       10  0002592  7702032253135    5  2023-10-19  TRAIN  6.0   \n",
       "\n",
       "                   ID  \n",
       "0  10-0002592-0002592  \n",
       "1  10-0002592-0002592  \n",
       "2  10-0002592-0002592  \n",
       "3  10-0002592-0002592  \n",
       "4  10-0002592-0002592  \n",
       "5  10-0002592-0002592  \n",
       "6  10-0002592-0002592  \n",
       "7  10-0002592-0002592  \n",
       "8  10-0002592-0002592  \n",
       "9  10-0002592-0002592  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5d1f1d5-c3d6-4574-8abd-f5534f4cf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Model():\n",
    "    def transform_input(self,dataset):\n",
    "        return dataset[\"y\"].values\n",
    "    def fit(self, data):\n",
    "        return []\n",
    "    def predict(self, data)-> pd.DataFrame:\n",
    "        return []\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        return []\n",
    "    def __call__(self, data)-> pd.DataFrame:\n",
    "        return self.predict(data)\n",
    "    def apply_format(self, pronostico):\n",
    "        pronostico = np.round(pronostico, 2)\n",
    "        pronostico = np.where((pronostico < 0) | np.isnan(pronostico) | np.isinf(pronostico), 0, pronostico)\n",
    "        return pronostico\n",
    "class PD_MEDIA(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"MEDIA\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.model = np.mean(self.transform_input(data))\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "    def predict(self, data):\n",
    "        return self.apply_format([self.model]*len(data))\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        return self.apply_format(self.model)\n",
    "    \n",
    "class PD_ARIMA(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"ARIMA\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.model = AutoARIMA().fit(y = self.transform_input(data))\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "    def predict(self, data):\n",
    "        pronostico = self.model.predict(len(data))\n",
    "        return self.apply_format(pronostico)\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        pronostico = self.model.predict_in_sample()\n",
    "        return self.apply_format(pronostico)\n",
    "    \n",
    "class PD_SARIMAX(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"SARIMAX\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.train_len=len(data)\n",
    "        self.model = SARIMAX(endog = self.transform_input(data),\n",
    "                            order = (0,0,0),\n",
    "                            seasonal_order = (0,1,0,7),\n",
    "                            suppress_warnings = True)\\\n",
    "                        .fit()\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "    def predict(self, data):\n",
    "        pronostico = self.model.forecast(len(data))\n",
    "        return self.apply_format(pronostico)\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        pronostico = self.model.predict(start=0, end=self.train_len-1)\n",
    "        return self.apply_format(pronostico)\n",
    "\n",
    "class PD_HOLTW(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"HOLTW\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.train_len=len(data)\n",
    "        self.model = ExponentialSmoothing( self.transform_input(data),\n",
    "                                     trend = \"mul\",\n",
    "                                     seasonal = \"mul\",\n",
    "                                     seasonal_periods = 7).fit()\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "    def predict(self, data):\n",
    "        pronostico = self.model.forecast(len(data))\n",
    "        return self.apply_format(pronostico)\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        pronostico = self.model.predict(start=0, end=self.train_len-1)\n",
    "        return self.apply_format(pronostico)\n",
    "        \n",
    "class PD_PROPHET(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"PROPHET\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.train_len=len(data)\n",
    "        data2 = data[[\"ds\",\"y\"]]\n",
    "        self.model = Prophet()\n",
    "        self.model.fit(data2)\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "    def predict(self, data):\n",
    "        data2 = data[[\"ds\",\"y\"]]\n",
    "        future_pd = self.model.make_future_dataframe(\n",
    "            periods=len(data2.values),\n",
    "            freq='d',\n",
    "            include_history = False\n",
    "        )\n",
    "        pronostico = self.model.predict(future_pd)\n",
    "        return self.apply_format(pronostico[\"yhat\"].values)\n",
    "    def back_prediction(self,)-> pd.DataFrame:\n",
    "        future_pd = self.model.make_future_dataframe(\n",
    "            periods=1,\n",
    "            freq='d',\n",
    "            include_history = True\n",
    "        )\n",
    "        results_pd = self.model.predict(future_pd)\n",
    "        return self.apply_format(results_pd[\"yhat\"].iloc[:-1])\n",
    "    \n",
    "class PD_TREES(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"TREES\"\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.col_names = [col for col in data.columns if col.startswith('C-')]\n",
    "        X, y = data[self.col_names], data[[\"y\"]]\n",
    "        self.model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        self.model.fit(X, y)\n",
    "        self.back = self.model.predict(X)\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "        self.most_recent_data = data.tail(1)[self.col_names]\n",
    "    def predict(self, data):\n",
    "#         pronostico = self.model.predict(data[self.col_names])\n",
    "#         return self.apply_format(pronostico)\n",
    "    \n",
    "        num_days = len(data)\n",
    "        most_recent_data = self.most_recent_data\n",
    "        if not hasattr(self, 'model'):\n",
    "            raise ValueError(\"The model has not been trained. Call the 'fit' method first.\")\n",
    "        if num_days <= 0:\n",
    "            raise ValueError(\"Number of days to forecast must be a positive integer.\")\n",
    "        \n",
    "        # Get the most recent data point to use as a starting point for forecasting\n",
    "          # Assuming 'data' is the same data used in 'fit'\n",
    "        \n",
    "        forecasts = []\n",
    "        for _ in range(num_days):\n",
    "            forecasted_value = self.model.predict(most_recent_data)[0]\n",
    "            forecasts.append(forecasted_value)\n",
    "            # Update the most recent data with the forecasted value\n",
    "            most_recent_data = most_recent_data.shift(-1).fillna(forecasted_value)\n",
    "        \n",
    "        return self.apply_format(forecasts)\n",
    "    def back_prediction(self,)-> pd.DataFrame:     \n",
    "        return self.apply_format(self.back)\n",
    "    \n",
    "\n",
    "class PD_MLP(Model):\n",
    "    def __init__(self):\n",
    "        self.name = \"MLP\"\n",
    "        self.structure = (20, 5)\n",
    "    def fit(self, data):\n",
    "        start_time = time.time()\n",
    "        self.col_names = [col for col in data.columns if col.startswith('C-')]\n",
    "        X, y = data[self.col_names], data[[\"y\"]]\n",
    "        self.model = MLPRegressor(hidden_layer_sizes= self.structure, activation='relu', random_state=42)\n",
    "        self.model.fit(X, y.values.ravel(),)  # MLPRegressor expects 1D array for y\n",
    "        self.back = self.model.predict(X)\n",
    "        end_time = time.time()\n",
    "        self.time = end_time - start_time\n",
    "        self.most_recent_data = data.tail(1)[self.col_names]\n",
    "    \n",
    "    def predict(self, data):\n",
    "        num_days = len(data)\n",
    "        most_recent_data = self.most_recent_data\n",
    "        if not hasattr(self, 'model'):\n",
    "            raise ValueError(\"The model has not been trained. Call the 'fit' method first.\")\n",
    "        if num_days <= 0:\n",
    "            raise ValueError(\"Number of days to forecast must be a positive integer.\")\n",
    "        \n",
    "        # Get the most recent data point to use as a starting point for forecasting\n",
    "          # Assuming 'data' is the same data used in 'fit'\n",
    "        \n",
    "        forecasts = []\n",
    "        for _ in range(num_days):\n",
    "            forecasted_value = self.model.predict(most_recent_data)[0]\n",
    "            forecasts.append(forecasted_value)\n",
    "            # Update the most recent data with the forecasted value\n",
    "            most_recent_data = most_recent_data.shift(-1).fillna(forecasted_value)\n",
    "        \n",
    "        return self.apply_format(forecasts)\n",
    "    \n",
    "    def back_prediction(self) -> pd.DataFrame:\n",
    "        return self.apply_format(self.back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03830be0-44c0-4035-a03f-330736b328dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_columns(df, column_name, num_lags):\n",
    "    for i in range(1, num_lags + 1):\n",
    "        df[f'C-{i}'] = df[column_name].shift(i)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "models = [\n",
    "    PD_HOLTW(),\n",
    "    PD_PROPHET(),\n",
    "    PD_SARIMAX(),\n",
    "    PD_MEDIA(),\n",
    "    PD_ARIMA(),\n",
    "#     PD_TREES(),\n",
    "#     PD_MLP(),\n",
    "#     PD_MLP2(),\n",
    "#     PD_MLP3(),\n",
    "#     PD_MLP4(),\n",
    "#     PD_MLP5(),\n",
    "]\n",
    "def find_key_with_min_value(my_dict):\n",
    "    \"\"\"\n",
    "    Find the key with the minimum value in a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        my_dict (dict): The input dictionary.\n",
    "    \n",
    "    Returns:\n",
    "        The key with the minimum value.\n",
    "    \"\"\"\n",
    "    min_key = None\n",
    "    min_value = float('inf')\n",
    "    \n",
    "    for key, value in my_dict.items():\n",
    "        if value < min_value:\n",
    "            min_key = key\n",
    "            min_value = value\n",
    "    \n",
    "    return min_key\n",
    "def forecast_generator(models):\n",
    "\n",
    "    def fn_forecast(data : pd.DataFrame) -> pd.DataFrame:\n",
    "        data = data.sort_values(\"ds\")\n",
    "#         data = create_lagged_columns(data, \"y\", 5)\n",
    "        data_train = data.query('TIPO == \"TRAIN\"')\\\n",
    "                         .sort_values(\"ds\")\n",
    "        data_test = data.query('TIPO == \"TEST\"')\\\n",
    "                        .sort_values(\"ds\")\\\n",
    "                        .reset_index()\n",
    "        \n",
    "        data_forecast = data_test[[\"LOCAL_ID\", \"ITEM_ID\", \"EAN\", \"ds\", \"y\"]]\n",
    "        \n",
    "        mape_scores = {}\n",
    "        rmse_scores = {}\n",
    "        flag_mape = False\n",
    "        mape_limit = COTA_MAPE_MODELS\n",
    "        n_models_ensemble = ENSEMBLE\n",
    "        \n",
    "        for index, model in enumerate(models):\n",
    "            if(flag_mape and index>=n_models_ensemble):\n",
    "                data_forecast[f\"F_{model.name}\"] = data_forecast[f\"F_{models[0].name}\"]\n",
    "                mape_scores[model.name] = mape * 1.1\n",
    "                rmse_scores[model.name] = rmse * 1.1\n",
    "            model.fit(data_train)\n",
    "            predictions = model.predict(data_test).reshape(-1)\n",
    "#             print(predictions, data_test['y'])\n",
    "            \n",
    "            data_forecast[f\"F_{model.name}\"] = predictions\n",
    "    \n",
    "            # Calculate MAPE\n",
    "            absolute_errors = np.abs(data_test['y'] - predictions)\n",
    "\n",
    "            percentage_errors = (absolute_errors / data_test['y']) * 100\n",
    "            mape = np.mean(percentage_errors)\n",
    "            mape_scores[model.name] = mape\n",
    "            \n",
    "            # Calculate RMSE\n",
    "            try:\n",
    "                rmse = sqrt(mean_squared_error(data_test['y'], predictions))\n",
    "            except ValueError:\n",
    "                rmse = float('inf')\n",
    "            rmse_scores[model.name] = rmse\n",
    "            \n",
    "            if mape < mape_limit:\n",
    "                flag_mape = True\n",
    "        \n",
    "        tmp = data_forecast[[f\"F_{m.name}\" for m in models[:n_models_ensemble]]].loc[:, (data_forecast != 0).any(axis=0)].mean(axis=1)\n",
    "        tmp = np.round(tmp, 2)\n",
    "        data_forecast[\"F_ENSEMBLE\"] = np.where((tmp < 0) | (np.isnan(tmp)), 0, tmp)\n",
    "        \n",
    "        # Calculate MAPE and RMSE for the ensemble model\n",
    "        absolute_errors_ensemble = np.abs(data_test['y'] - data_forecast[\"F_ENSEMBLE\"])\n",
    "        percentage_errors_ensemble = (absolute_errors_ensemble / data_test['y']) * 100\n",
    "        mape_ensemble = np.mean(percentage_errors_ensemble)\n",
    "        try:\n",
    "            rmse_ensemble = sqrt(mean_squared_error(data_test['y'], data_forecast[\"F_ENSEMBLE\"]))\n",
    "        except ValueError:\n",
    "            rmse_ensemble =  float('inf')\n",
    "        mape_scores[\"ENSEMBLE\"] = mape_ensemble\n",
    "        rmse_scores[\"ENSEMBLE\"] = rmse_ensemble\n",
    "                \n",
    "        # Find the best model according to RMSE and MAPE\n",
    "        best_model_mape = find_key_with_min_value(mape_scores)\n",
    "        best_model_rmse = find_key_with_min_value(rmse_scores)\n",
    "        \n",
    "        data_forecast[\"RMSE\"] = best_model_rmse\n",
    "        data_forecast[\"MAPE\"] = best_model_mape\n",
    "        data_forecast[\"RMSE_VALUE\"] = rmse_scores[best_model_rmse]\n",
    "        data_forecast[\"MAPE_VALUE\"] = mape_scores[best_model_mape]\n",
    "                               \n",
    "        return data_forecast\n",
    "    \n",
    "    return fn_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc56f2dd-4d95-4739-af4f-4e2d0d7552e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estructura_forecast = StructType([\n",
    "    StructField(\"LOCAL_ID\", StringType()),\n",
    "    StructField(\"ITEM_ID\", StringType()),\n",
    "    StructField(\"EAN\", StringType()),\n",
    "    StructField(\"ds\", DateType()),\n",
    "    StructField(\"y\", DoubleType()),\n",
    "    *[StructField(f\"F_{m.name}\", DoubleType()) for m in models],\n",
    "    StructField(\"F_ENSEMBLE\", DoubleType()),\n",
    "    StructField(\"RMSE\", StringType()),\n",
    "    StructField(\"MAPE\", StringType()),\n",
    "    StructField(\"RMSE_VALUE\", DoubleType()),\n",
    "    StructField(\"MAPE_VALUE\", DoubleType()),\n",
    "])\n",
    "\n",
    "# Se obtiene la data mape \n",
    "data_forecast = data_outliers\\\n",
    "    .groupBy(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\")\\\n",
    "    .applyInPandas(forecast_generator(models), schema = estructura_forecast )\\\n",
    "    .withColumn(\"FECHA_EJECUCION\", F.lit(fecha_ejecucion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f42fdd-5316-41e8-9218-fe40bbe38071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>EAN</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>F_HOLTW</th>\n",
       "      <th>F_PROPHET</th>\n",
       "      <th>F_SARIMAX</th>\n",
       "      <th>F_MEDIA</th>\n",
       "      <th>F_ARIMA</th>\n",
       "      <th>F_ENSEMBLE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE_VALUE</th>\n",
       "      <th>MAPE_VALUE</th>\n",
       "      <th>FECHA_EJECUCION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.92</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.92</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.16</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.20</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.93</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.07</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.82</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>0.695259</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0027749</td>\n",
       "      <td>7703812101356</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.30</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>3.195117</td>\n",
       "      <td>32.011905</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0027749</td>\n",
       "      <td>7703812101356</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.62</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>3.195117</td>\n",
       "      <td>32.011905</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0027749</td>\n",
       "      <td>7703812101356</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.78</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>3.195117</td>\n",
       "      <td>32.011905</td>\n",
       "      <td>2024-05-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCAL_ID  ITEM_ID            EAN          ds     y  F_HOLTW  F_PROPHET  \\\n",
       "0       10  0013996  7702506112197  2024-05-13   2.0     1.95       1.88   \n",
       "1       10  0013996  7702506112197  2024-05-14   1.0     1.97       1.88   \n",
       "2       10  0013996  7702506112197  2024-05-15   1.0     1.23       1.10   \n",
       "3       10  0013996  7702506112197  2024-05-16   1.0     1.25       1.16   \n",
       "4       10  0013996  7702506112197  2024-05-17   2.0     1.96       1.90   \n",
       "5       10  0013996  7702506112197  2024-05-18   1.0     2.11       2.03   \n",
       "6       10  0013996  7702506112197  2024-05-19   4.0     2.85       2.78   \n",
       "7       10  0027749  7703812101356  2024-05-13  10.0     3.41       3.20   \n",
       "8       10  0027749  7703812101356  2024-05-14   2.0     2.79       2.45   \n",
       "9       10  0027749  7703812101356  2024-05-15   3.0     2.96       2.61   \n",
       "\n",
       "   F_SARIMAX  F_MEDIA  F_ARIMA  F_ENSEMBLE     RMSE     MAPE  RMSE_VALUE  \\\n",
       "0        1.0     1.94     2.61        1.92  PROPHET  PROPHET    0.695259   \n",
       "1        2.0     1.94     2.27        1.92  PROPHET  PROPHET    0.695259   \n",
       "2        1.0     1.94     1.98        1.16  PROPHET  PROPHET    0.695259   \n",
       "3        1.0     1.94     1.72        1.20  PROPHET  PROPHET    0.695259   \n",
       "4        2.0     1.94     1.50        1.93  PROPHET  PROPHET    0.695259   \n",
       "5        3.0     1.94     1.30        2.07  PROPHET  PROPHET    0.695259   \n",
       "6        3.0     1.94     1.13        2.82  PROPHET  PROPHET    0.695259   \n",
       "7        4.0     4.94     2.59        3.30  PROPHET  PROPHET    3.195117   \n",
       "8        2.0     4.94     4.20        2.62  PROPHET  PROPHET    3.195117   \n",
       "9        1.0     4.94     3.38        2.78  PROPHET  PROPHET    3.195117   \n",
       "\n",
       "   MAPE_VALUE FECHA_EJECUCION  \n",
       "0   36.928571      2024-05-20  \n",
       "1   36.928571      2024-05-20  \n",
       "2   36.928571      2024-05-20  \n",
       "3   36.928571      2024-05-20  \n",
       "4   36.928571      2024-05-20  \n",
       "5   36.928571      2024-05-20  \n",
       "6   36.928571      2024-05-20  \n",
       "7   32.011905      2024-05-20  \n",
       "8   32.011905      2024-05-20  \n",
       "9   32.011905      2024-05-20  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if MONDAY:\n",
    "#     data_forecast.write.mode(\"overwrite\").parquet(f\"gs://{ENV}-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_forecast\")\n",
    "data_forecast = spark.read.parquet(f\"gs://{ENV}-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_forecast\")\n",
    "display(data_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60d97c98-1bd7-4581-9685-82fa11c1b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mape = data_forecast.groupBy(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\").agg(F.first(\"MAPE\").alias(\"MODELO\"),\n",
    "                                                                    F.first(\"MAPE_VALUE\").alias(\"MAPE\"),\n",
    "                                                                    F.first(\"RMSE_VALUE\").alias(\"RMSE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab6dd881-7136-4902-a090-c5d1107a5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>EAN</th>\n",
       "      <th>MODELO</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0000633</td>\n",
       "      <td>482</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>67.924150</td>\n",
       "      <td>0.562374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0007061</td>\n",
       "      <td>7702085012246</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>0.830258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0007172</td>\n",
       "      <td>7702085013076</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>78.265201</td>\n",
       "      <td>4.097834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0007934</td>\n",
       "      <td>7702047003497</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>36.142857</td>\n",
       "      <td>0.363613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0008430</td>\n",
       "      <td>7702231000035</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>1.448684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0010047</td>\n",
       "      <td>7702035432117</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>1.281210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0010056</td>\n",
       "      <td>7702035432339</td>\n",
       "      <td>ENSEMBLE</td>\n",
       "      <td>51.611284</td>\n",
       "      <td>20.638907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>0.695259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0016841</td>\n",
       "      <td>7702432002005</td>\n",
       "      <td>ENSEMBLE</td>\n",
       "      <td>20.360806</td>\n",
       "      <td>2.784536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0027744</td>\n",
       "      <td>7703812101103</td>\n",
       "      <td>HOLTW</td>\n",
       "      <td>34.017007</td>\n",
       "      <td>1.245695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCAL_ID  ITEM_ID            EAN    MODELO       MAPE       RMSE\n",
       "0       10  0000633            482   SARIMAX  67.924150   0.562374\n",
       "1       10  0007061  7702085012246   SARIMAX  57.142857   0.830258\n",
       "2       10  0007172  7702085013076   PROPHET  78.265201   4.097834\n",
       "3       10  0007934  7702047003497     ARIMA  36.142857   0.363613\n",
       "4       10  0008430  7702231000035   SARIMAX  42.857143   1.448684\n",
       "5       10  0010047  7702035432117   SARIMAX  28.571429   1.281210\n",
       "6       10  0010056  7702035432339  ENSEMBLE  51.611284  20.638907\n",
       "7       10  0013996  7702506112197   PROPHET  36.928571   0.695259\n",
       "8       10  0016841  7702432002005  ENSEMBLE  20.360806   2.784536\n",
       "9       10  0027744  7703812101103     HOLTW  34.017007   1.245695"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "245f01b7-5690-4cd7-911b-97ade5d2226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "average_MAPE = data_mape.select(F.avg(\"MAPE\")).collect()[0][0]\n",
    "average_RMSE = data_mape.select(F.avg(\"RMSE\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "293d5442-7870-40e1-aa7f-9b2854a11334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.78130924809774 2.346254104550151\n"
     ]
    }
   ],
   "source": [
    "print(average_MAPE,average_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d7ea1f7-b4ae-4120-b057-edb54894cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelos = data_outliers\\\n",
    "                    .join(data_mape,\n",
    "                          how = \"left\",\n",
    "                          on = [\"LOCAL_ID\", \"ITEM_ID\", \"EAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbf56be4-7538-407c-ac15-f55a702e1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umv_generator(models):\n",
    "\n",
    "    def fn_forecast(data : pd.DataFrame) -> pd.DataFrame:\n",
    "        data = data.sort_values(\"ds\")\n",
    "        data = create_lagged_columns(data, \"y\", 10)\n",
    "        \n",
    "        data_train = data.query('TIPO != \"VALIDATE\"')\\\n",
    "                         .sort_values(\"ds\")\n",
    "        data_test = data.query('TIPO == \"VALIDATE\"')\\\n",
    "                        .sort_values(\"ds\")\\\n",
    "                        .reset_index()\n",
    "\n",
    "        model_selected = data[\"MODELO\"].iloc[0]\n",
    "        n_models_ensemble = ENSEMBLE\n",
    "        data_forecast = data_test[[\"LOCAL_ID\", \"ITEM_ID\", \"EAN\", \"ds\", \"MODELO\", \"MAPE\"]]\n",
    "\n",
    "        \n",
    "        model = None\n",
    "        for m in models:\n",
    "            if m.name == model_selected:\n",
    "                model = m\n",
    "                break\n",
    "        if model:\n",
    "            model.fit(data_train)\n",
    "            data_forecast[f\"VALIDATE\"] = model.predict(data_test)\n",
    "        else:\n",
    "            for m in models[:n_models_ensemble]:\n",
    "                m.fit(data_train)\n",
    "                data_forecast[f\"F_{m.name}\"] = m.predict(data_test)\n",
    "\n",
    "            tmp = data_forecast[[f\"F_{m.name}\" for m in models[:n_models_ensemble]]].loc[:, (data_forecast != 0).any(axis=0)].mean(axis=1)\n",
    "            tmp = np.round(tmp, 2)\n",
    "            data_forecast[\"VALIDATE\"] = np.where( (tmp < 0) | (np.isnan(tmp)), 0, tmp)\n",
    "            data_forecast = data_forecast.drop(columns=[f\"F_{m.name}\" for m in models[:n_models_ensemble]])\n",
    "        return data_forecast\n",
    "    return fn_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef7e3890-f415-4a0a-b3e8-cf5910adcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la cota del mape\n",
    "cota_mape = 0.35\n",
    "\n",
    "# Se define la significancia\n",
    "alpha = 0.10\n",
    "z_alpha = np.round(sps.norm.ppf(1-(alpha/2)), 2)\n",
    "\n",
    "# Se definen los cortes para la data final\n",
    "cota_inferior_pronostico = 4\n",
    "cota_superior_mape = 31\n",
    "cota_inferior_mape = 4\n",
    "\n",
    "# Se define la estructura de la data mape\n",
    "estructura_umv = StructType([\n",
    "    StructField(\"LOCAL_ID\", StringType()),\n",
    "    StructField(\"ITEM_ID\", StringType()),\n",
    "    StructField(\"EAN\", StringType()),\n",
    "    StructField(\"ds\", DateType()),\n",
    "    StructField(\"MODELO\", StringType()),\n",
    "    StructField(\"MAPE\", DoubleType()),\n",
    "    StructField(\"VALIDATE\", DoubleType())\n",
    "])\n",
    "\n",
    "# Se obtiene la data mape \n",
    "data_output = data_modelos\\\n",
    "               .groupBy(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\")\\\n",
    "               .applyInPandas(umv_generator(models), schema = estructura_umv)\\\n",
    "               .withColumn(\"UMV\", \n",
    "                           F.when(F.col(\"MAPE\")/100 <= F.lit(cota_mape), F.round(F.col(\"VALIDATE\")*(1 - 2*F.col(\"MAPE\")/100),2))\\\n",
    "                            .otherwise(F.round(F.col(\"VALIDATE\") - (F.lit(z_alpha)*F.col(\"MAPE\")/100)/sqrt(7),2)))\\\n",
    "               .withColumn(\"UMV\",\n",
    "                           F.when(F.col(\"UMV\") <= 1, 1)\\\n",
    "                            .otherwise(F.col(\"UMV\")))\\\n",
    "               .withColumn(\"DIA_SEMANA\", F.dayofweek(F.col(\"ds\")))\\\n",
    "               .withColumn(\"DIA\",\n",
    "                           F.when(F.col(\"DIA_SEMANA\") == 2, \"LUNES\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 3, \"MARTES\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 4, \"MIERCOLES\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 5, \"JUEVES\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 6, \"VIERNES\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 7, \"SABADO\")\\\n",
    "                            .when(F.col(\"DIA_SEMANA\") == 1, \"DOMINGO\"))\\\n",
    "               .select(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\", \"ds\", \"DIA\", \"DIA_SEMANA\",\n",
    "                       \"VALIDATE\", \"UMV\", \"MAPE\", \"MODELO\")\\\n",
    "               .withColumn(\"UMV\", F.floor(F.col(\"UMV\")))\\\n",
    "               .withColumn(\"MAPE\", F.floor(F.col(\"MAPE\")))\\\n",
    "               .withColumn(\"VALIDATE\", F.floor(F.col(\"VALIDATE\")))\\\n",
    "               .filter((F.col(\"VALIDATE\") > F.lit(cota_inferior_pronostico)) &\n",
    "                       (F.col(\"MAPE\") < F.lit(cota_superior_mape)) & \n",
    "                       (F.col(\"MAPE\") > F.lit(cota_inferior_mape)))\\\n",
    "               .join(data_transaccional\\\n",
    "                         .select(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\")\\\n",
    "                         .distinct()\\\n",
    "                         .withColumnRenamed(\"ds\", \"Fecha\"),\n",
    "                     on = [\"LOCAL_ID\", \"ITEM_ID\", \"EAN\"],\n",
    "                     how = \"left\")\\\n",
    "                .withColumnRenamed(\"ds\", \"DATE\")\\\n",
    "                .select(\"LOCAL_ID\", \"ITEM_ID\", \"EAN\", \"DATE\", \"DIA\", \"DIA_SEMANA\",\n",
    "                        \"VALIDATE\", \"UMV\", \"MAPE\", \"MODELO\").withColumnRenamed(\"VALIDATE\",\"FORECAST\")\\\n",
    "                .withColumnRenamed(\"DIA\",\"DAY\")\\\n",
    "                .withColumnRenamed(\"DIA_SEMANA\",\"WEEK_DAY\")\\\n",
    "                .withColumnRenamed(\"MODELO\",\"MODEL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620447b-70d3-4acf-8787-f002c6159d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if MONDAY:\n",
    "#     data_output.write.mode(\"overwrite\").parquet(\"/tmp/co/sm/data_output\")\n",
    "#     data_output = spark.read.parquet(\"/tmp/co/sm/data_output\")\n",
    "#     tmpd = data_output.groupBy(\"MODEL\").count().toPandas()\n",
    "#     tmpd.sort_values(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de59ce-0499-40a2-a950-cbc22c43dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# if MONDAY:\n",
    "data_output.write.parquet(f\"gs://{ENV}-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_output_umv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981f0a1-7334-473b-8b98-62af6e03c0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: gs://staging-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_output_um",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_output \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mENV\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_output_um\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:458\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    453\u001b[0m recursiveFileLookup \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursiveFileLookup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema, pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[1;32m    455\u001b[0m                recursiveFileLookup\u001b[38;5;241m=\u001b[39mrecursiveFileLookup, modifiedBefore\u001b[38;5;241m=\u001b[39mmodifiedBefore,\n\u001b[1;32m    456\u001b[0m                modifiedAfter\u001b[38;5;241m=\u001b[39mmodifiedAfter)\n\u001b[0;32m--> 458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: gs://staging-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_output_um"
     ]
    }
   ],
   "source": [
    "data_output = spark.read.parquet(f\"gs://{ENV}-bucket-dataproc-bigquery/dataproc/umv/tmp/co/sm/data_output_um\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6989b64-7d60-46ed-80b3-32dc19aa541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41ac5fb-bde2-48a9-af82-c0d9dde0d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-25</td>\n",
       "      <td>6002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>4138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>3872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>4006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>4137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>5743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>4493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  count\n",
       "0  2024-05-26   5376\n",
       "1  2024-05-25   6002\n",
       "2  2024-05-24   4138\n",
       "3  2024-05-23   3872\n",
       "4  2024-05-22   4006\n",
       "5  2024-05-21   4137\n",
       "6  2024-05-20   4601\n",
       "7  2024-04-07   5743\n",
       "8  2024-04-06   5794\n",
       "9  2024-04-05   4493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if MONDAY:\n",
    "data_output = spark.read.format(\"bigquery\").option(\"table\", \"data_analytics_default.BQ_CO_SM_UMV_01\").load()\n",
    "display(data_output.groupBy(\"DATE\").count().orderBy(F.col(\"DATE\").desc()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e791aace-d899-420d-8787-f31d6013a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCAL_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>EAN</th>\n",
       "      <th>MODELO</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0013996</td>\n",
       "      <td>7702506112197</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>27.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0027749</td>\n",
       "      <td>7703812101356</td>\n",
       "      <td>HOLTW</td>\n",
       "      <td>28.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0851911</td>\n",
       "      <td>7702001106660</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0963186</td>\n",
       "      <td>7702766098057</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>27.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3251527</td>\n",
       "      <td>7707237414091</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>3328671</td>\n",
       "      <td>7703616274645</td>\n",
       "      <td>HOLTW</td>\n",
       "      <td>49.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103</td>\n",
       "      <td>0005010</td>\n",
       "      <td>7702137630206</td>\n",
       "      <td>HOLTW</td>\n",
       "      <td>33.130952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103</td>\n",
       "      <td>0007466</td>\n",
       "      <td>7702001044122</td>\n",
       "      <td>ENSEMBLE</td>\n",
       "      <td>26.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103</td>\n",
       "      <td>0099670</td>\n",
       "      <td>7702001121748</td>\n",
       "      <td>PROPHET</td>\n",
       "      <td>51.145238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103</td>\n",
       "      <td>0245696</td>\n",
       "      <td>7702026062163</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>105.726984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCAL_ID  ITEM_ID            EAN    MODELO        MAPE\n",
       "0       10  0013996  7702506112197   PROPHET   27.880952\n",
       "1       10  0027749  7703812101356     HOLTW   28.842857\n",
       "2       10  0851911  7702001106660   SARIMAX   14.285714\n",
       "3       10  0963186  7702766098057   PROPHET   27.785714\n",
       "4       10  3251527  7707237414091   SARIMAX   78.571429\n",
       "5       10  3328671  7703616274645     HOLTW   49.071429\n",
       "6      103  0005010  7702137630206     HOLTW   33.130952\n",
       "7      103  0007466  7702001044122  ENSEMBLE   26.407143\n",
       "8      103  0099670  7702001121748   PROPHET   51.145238\n",
       "9      103  0245696  7702026062163     MEDIA  105.726984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    data_mape = spark.read.parquet(\"/tmp/co/sm/data_mape\")\n",
    "    display(data_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea70aed-659b-487c-8f3d-3809e9f22d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.98317382053177"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score = data_mape.select(F.avg(\"MAPE\")).collect()[0][0]\n",
    "average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe26367-1b15-46a4-8eb5-6ac0855fad8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
